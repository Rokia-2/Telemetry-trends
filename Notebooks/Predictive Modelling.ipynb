{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c818017",
   "metadata": {},
   "source": [
    "## Building a Regression Model for Predicting Sensor Readings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9dd352",
   "metadata": {},
   "source": [
    "In this section, we focus on building a predictive model to forecast sensor readings or detect anomalies in IoT device behavior. We apply machine learning techniques to the cleaned and processed data, selecting appropriate features and evaluating multiple models. The goal is to identify patterns and create a model that can predict future sensor values or classify device states as \"normal\" or \"anomalous\". This step demonstrates the potential for using predictive analytics to improve the monitoring and maintenance of IoT devices over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003dc3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import py4j\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Creating a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IoT Telemetry Data \") \\\n",
    "    .getOrCreate()\n",
    "df = spark.read.csv('iot_telemetry_data.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a818a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Select feature columns and target column\n",
    "feature_columns = ['humidity', 'co', 'smoke', 'light', 'motion', 'lpg']\n",
    "target_column = 'temp'\n",
    "\n",
    "# Assemble features into a single vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df_prepared = assembler.transform(df).select(\"features\", target_column)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = df_prepared.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc7148a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [-0.11461735749535866,-5642.605482291604,8604.974519034318,4.6731200460259,0.4731788247748365,-19522.889818307012]\n",
      "Intercept:  29.791743264227286\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Linear Regression model\n",
    "lr = LinearRegression(labelCol=target_column, featuresCol=\"features\")\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Model summary\n",
    "print(\"Coefficients: \", lr_model.coefficients)\n",
    "print(\"Intercept: \", lr_model.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb20720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE): 1.253896108353969\n",
      "+------------------+------------------+\n",
      "|        prediction|              temp|\n",
      "+------------------+------------------+\n",
      "| 31.92687960048898|26.799999237060547|\n",
      "|31.820708238643398|23.600000381469727|\n",
      "| 31.81651900516062|23.600000381469727|\n",
      "|30.346290084333667|19.299999237060547|\n",
      "|30.144903590771058|24.399999618530273|\n",
      "|25.386563129014583|              19.5|\n",
      "|29.980188553405846|25.399999618530273|\n",
      "|29.851896566782564|26.399999618530273|\n",
      "| 22.78477172746023|              22.8|\n",
      "|22.783718401990065|              22.7|\n",
      "| 22.78306621065139|              22.8|\n",
      "| 22.78281727811288|              22.9|\n",
      "| 22.78197978544234|              22.7|\n",
      "|22.781304531980716|              22.9|\n",
      "|22.781041530158923|              22.8|\n",
      "+------------------+------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model using Root Mean Square Error (RMSE)\n",
    "evaluator = RegressionEvaluator(labelCol=target_column, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse}\")\n",
    "\n",
    "# Show predictions vs actuals\n",
    "predictions.select(\"prediction\", target_column).show(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67ce537",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc0eb02",
   "metadata": {},
   "source": [
    "This IoT telemetry project highlights the power of data analysis and machine learning in monitoring and optimizing device performance. Starting with data exploration, we gained a deep understanding of the dataset's structure and underlying patterns through descriptive statistics, visualizations, and correlation analysis. This laid the groundwork for identifying significant relationships and trends among the metrics.\n",
    "\n",
    "In the time-series analysis, we examined key metrics over time, uncovering trends, peaks, and anomalies that could indicate device irregularities or external factors influencing performance. This step provided actionable insights into the temporal behavior of sensors.\n",
    "\n",
    "Next, we conducted anomaly detection, leveraging Z-scores to pinpoint outliers across the dataset. These outliers can signal unusual conditions, enabling proactive responses to potential issues and optimizing device uptime.\n",
    "\n",
    "Finally, we implemented a predictive model, demonstrating the potential to forecast future sensor readings or detect anomalous states. Such capabilities can significantly enhance real-time monitoring and maintenance, reducing operational risks and costs.\n",
    "\n",
    "The project underscores the importance of data-driven solutions in IoT ecosystems. As the dataset grows over time, transitioning to scalable tools like PySpark ensures robust processing capabilities. Additionally, the techniques used here—EDA, anomaly detection, and predictive modeling—serve as a foundation for real-world IoT analytics, empowering businesses to achieve smarter device management and improved system reliability.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
